{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from PIL import Image\n",
    "from pylab import *\n",
    "import cv2\n",
    "from scipy.ndimage import  filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/nick/Downloads/chess_data/train'\n",
    "val_dir = '/Users/nick/Downloads/chess_data/val'\n",
    "test_dir = '/Users/nick/Downloads/chess_data/test'\n",
    "#data_dir = '/Users/nick/Downloads/chess_data/data'\n",
    "\n",
    "#классы\n",
    "black_pawn = 'black_pawn'\n",
    "empty = 'empty'\n",
    "img_width, img_height = 720, 720\n",
    "input_shape = (img_width, img_height, 3)\n",
    "epochs = 3\n",
    "batch_size = 30\n",
    "\n",
    "# test_data_portion = 0.15\n",
    "# val_data_portion = 0.15\n",
    "# nb_images = 60\n",
    "\n",
    "nb_train_samples = 137\n",
    "nb_validation_samples = 19\n",
    "nb_test_samples = 31\n",
    "\n",
    "sigma = 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image = cv2.imread('/Users/nick/Downloads/chess_data/current_test/test_image.jpg', 3)\n",
    "# cv2.resize(test_image, (720, 720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# black_pawns = 'black_pawns'\n",
    "# empty = 'empty'\n",
    "# start_val_data_idx = int(nb_images * (1 - val_data_portion - test_data_portion))\n",
    "# start_test_data_idx = int(nb_images * (1 - test_data_portion))\n",
    "# print(start_test_data_idx, start_val_data_idx)# def copy_images(start_index, end_index, source_dir, dest_dir, chess_class):\n",
    "#     i = 0\n",
    "#     for fn in os.listdir(source_dir):\n",
    "#         if fn == '.DS_Store':\n",
    "#             continue\n",
    "#         if i < start_index:\n",
    "#             continue\n",
    "#         if i >= end_index:\n",
    "#             break\n",
    "#         shutil.copy2(source_dir, os.path.join(dest_dir, chess_class))\n",
    "#         i += 1\n",
    "# copy_images(0, start_val_data_idx, data_dir, val_data, black_pawns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(folder_name, class_name):\n",
    "    for fn in os.listdir(folder_name + '/' + class_name):\n",
    "        if fn == '.DS_Store':\n",
    "            continue\n",
    "        im = np.array(Image.open(os.path.join(folder_name + '/' + class_name + '/' + fn)).convert('L'))\n",
    "        im = cv2.resize(im, (720, 720))\n",
    "#         imx = np.zeros(im.shape)\n",
    "#         filters.gaussian_filter(im, (sigma, sigma), (0, 1), imx)\n",
    "\n",
    "#         imy = np.zeros(im.shape)\n",
    "#         filters.gaussian_filter(im, (sigma, sigma), (1, 0), imy)\n",
    "\n",
    "#         magn = np.sqrt(imx**2 + imy**2)\n",
    "#         magn = np.uint8(magn)\n",
    "\n",
    "        cv2.imwrite(os.path.join(os.path.join(folder_name + '/' + class_name + '/' + fn)), im)\n",
    "\n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         plt.imshow(magn, cmap=plt.cm.binary)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(train_dir, black_pawn)\n",
    "process_images(train_dir, empty)\n",
    "\n",
    "process_images(test_dir, black_pawn)\n",
    "process_images(test_dir, empty)\n",
    "\n",
    "process_images(val_dir, black_pawn)\n",
    "process_images(val_dir, empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 137 images belonging to 2 classes.\n",
      "Found 19 images belonging to 2 classes.\n",
      "Found 31 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "# current_test =. datagen.flow_from_directory(\n",
    "#     current_test_dir,\n",
    "#     target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.6299 - acc: 0.5263\n",
      "5/5 [==============================] - 167s 33s/step - loss: 4.5689 - acc: 0.5474 - val_loss: 1.6299 - val_acc: 0.5263\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5602 - acc: 0.8947\n",
      "5/5 [==============================] - 164s 33s/step - loss: 1.0938 - acc: 0.5620 - val_loss: 0.5602 - val_acc: 0.8947\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.4291 - acc: 0.7368\n",
      "5/5 [==============================] - 263s 53s/step - loss: 0.4919 - acc: 0.8248 - val_loss: 0.4291 - val_acc: 0.7368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb476a6320>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятность распознавания на тестовых данных: 80.65%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n",
    "print(\"Вероятность распознавания на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ахует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
