{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from PIL import Image\n",
    "from pylab import *\n",
    "import cv2\n",
    "from scipy.ndimage import  filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directions\n",
    "\n",
    "train_dir = '/Users/nick/Downloads/chess_data/train'\n",
    "val_dir = '/Users/nick/Downloads/chess_data/val'\n",
    "test_dir = '/Users/nick/Downloads/chess_data/test'\n",
    "keys_image_dir = '/Users/nick/Downloads/chess_data/keys'\n",
    "\n",
    "# Arguments\n",
    "\n",
    "img_width, img_height = 720, 720\n",
    "input_shape = (img_width, img_height, 3)\n",
    "epochs = 2\n",
    "batch_size = 25\n",
    "sigma = 0.45\n",
    "test_images = 'test_images'\n",
    "\n",
    "# test_data_portion = 0.15\n",
    "# val_data_portion = 0.15\n",
    "# nb_images = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "\n",
    "black_pawn = 'black_pawn'\n",
    "black_bishop = 'black_bishop'\n",
    "black_knight = 'black_knight'\n",
    "black_rook = 'black_rook'\n",
    "black_king = 'black_king'\n",
    "black_queen = 'black_queen'\n",
    "\n",
    "white_pawn = 'white_pawn'\n",
    "white_bishop = 'white_bishop'\n",
    "white_knight = 'white_knight'\n",
    "white_rook = 'white_rook'\n",
    "white_king = 'white_king'\n",
    "white_queen = 'white_queen'\n",
    "\n",
    "empty = 'empty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split (pass)\n",
    "# black_pawns = 'black_pawns'\n",
    "# empty = 'empty'\n",
    "# start_val_data_idx = int(nb_images * (1 - val_data_portion - test_data_portion))\n",
    "# start_test_data_idx = int(nb_images * (1 - test_data_portion))\n",
    "# print(start_test_data_idx, start_val_data_idx)# def copy_images(start_index, end_index, source_dir, dest_dir, chess_class):\n",
    "#     i = 0\n",
    "#     for fn in os.listdir(source_dir):\n",
    "#         if fn == '.DS_Store':\n",
    "#             continue\n",
    "#         if i < start_index:\n",
    "#             continue\n",
    "#         if i >= end_index:\n",
    "#             break\n",
    "#         shutil.copy2(source_dir, os.path.join(dest_dir, chess_class))\n",
    "#         i += 1\n",
    "# copy_images(0, start_val_data_idx, data_dir, val_data, black_pawns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_white(folder_name, class_name):\n",
    "    for fn in os.listdir(folder_name + '/' + class_name):\n",
    "        if fn == '.DS_Store':\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(folder_name + '/' + class_name + '/' + fn))\n",
    "        im = cv2.resize(im, (720, 720))\n",
    "        im = cv2.Sobel(im,cv2.CV_8UC1,0,1,ksize=5)\n",
    "        \n",
    "        plt.imshow(im, cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "        \n",
    "        cv2.imwrite(os.path.join(os.path.join(folder_name + '/' + class_name + '/' + fn)), im)\n",
    "# Works worse\n",
    "#         lower_black = np.array([16,10,10])\n",
    "#         upper_black = np.array([255,255,255])\n",
    "\n",
    "#         mask = cv2.inRange(hsv, lower_black, upper_black)\n",
    "#         im = cv2.bitwise_and(im,im, mask = mask)\n",
    "        \n",
    "\n",
    "# Show\n",
    "#         plt.imshow(im, cmap = plt.cm.binary)\n",
    "#         plt.show()\n",
    "\n",
    "# Show bigger picture\n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         plt.imshow(im_test, cmap=plt.cm.binary)\n",
    "#         plt.show()\n",
    "\n",
    "# Dimension correction for tensorflow needs\n",
    "#         im_test.shape\n",
    "#         im_test = np.expand_dims(im_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_white(test_dir, white_king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_black(folder_name, class_name):\n",
    "    for fn in os.listdir(folder_name + '/' + class_name):\n",
    "        if fn == '.DS_Store':\n",
    "            continue\n",
    "        im = cv2.imread(os.path.join(folder_name + '/' + class_name + '/' + fn))\n",
    "        im = cv2.resize(im, (720, 720))\n",
    "        im = cv2.Sobel(im,cv2.CV_8UC1,0,1,ksize=5)\n",
    "        cv2.imwrite(os.path.join(os.path.join(folder_name + '/' + class_name + '/' + fn)), im)\n",
    "# Show\n",
    "#         plt.imshow(im, cmap=plt.cm.binary)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White pieces processing\n",
    "\n",
    "# process_white(train_dir, white_pawn)\n",
    "# process_white(train_dir, white_knight)\n",
    "# process_white(train_dir, white_rook)\n",
    "# process_white(train_dir, white_king)\n",
    "# process_white(train_dir, white_queen)\n",
    "# process_white(train_dir, white_bishop)\n",
    "\n",
    "# process_white(test_dir, white_pawn)\n",
    "# process_white(test_dir, white_knight)\n",
    "# process_white(test_dir, white_rook)\n",
    "# process_white(test_dir, white_king)\n",
    "# process_white(test_dir, white_queen)\n",
    "# process_white(test_dir, white_bishop)\n",
    "\n",
    "# process_white(val_dir, white_pawn)\n",
    "# process_white(val_dir, white_knight)\n",
    "# process_white(val_dir, white_rook)\n",
    "# process_white(val_dir, white_king)\n",
    "# process_white(val_dir, white_queen)\n",
    "# process_white(val_dir, white_bishop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black pieces processing (same as white)\n",
    "\n",
    "# process_black(train_dir, black_pawn)\n",
    "# process_black(train_dir, black_knight)\n",
    "# process_black(train_dir, black_rook)\n",
    "# process_black(train_dir, black_king)\n",
    "# process_black(train_dir, black_queen)\n",
    "# process_black(train_dir, black_bishop)\n",
    "# process_black(train_dir, empty)\n",
    "\n",
    "# process_black(test_dir, black_pawn)\n",
    "# process_black(test_dir, black_knight)\n",
    "# process_black(test_dir, black_rook)\n",
    "# process_black(test_dir, black_king)\n",
    "# process_black(test_dir, black_queen)\n",
    "# process_black(test_dir, black_bishop)\n",
    "# process_black(test_dir, empty)\n",
    "\n",
    "# process_black(val_dir, black_pawn)\n",
    "# process_black(val_dir, black_knight)\n",
    "# process_black(val_dir, black_rook)\n",
    "# process_black(val_dir, black_king)\n",
    "# process_black(val_dir, black_queen)\n",
    "# process_black(val_dir, black_bishop)\n",
    "# process_black(val_dir, empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 345 images belonging to 13 classes.\n",
      "Found 67 images belonging to 13 classes.\n",
      "Found 75 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define classes\n",
    "nb_train_samples = 345\n",
    "nb_validation_samples = 67\n",
    "nb_test_samples = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.0769 - acc: 0.9231\n",
      "14/14 [==============================] - 382s 27s/step - loss: 0.0882 - acc: 0.9010 - val_loss: 0.0769 - val_acc: 0.9231\n",
      "Epoch 2/2\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.0769 - acc: 0.9231\n",
      "14/14 [==============================] - 384s 27s/step - loss: 0.0769 - acc: 0.9231 - val_loss: 0.0769 - val_acc: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb92088f98>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятность распознавания на тестовых данных: 92.31%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "print(\"Вероятность распознавания на тестовых данных: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#omg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#checker (pass)\n",
    "#process_black(keys_image_dir, empty)\n",
    "# keys_generator = datagen.flow_from_directory(\n",
    "#     keys_image_dir,\n",
    "#     target_size=(img_width, img_height),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode='categorical')\n",
    "# model.predict(keys_generator, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
